{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lesson 17 - Data Cleaning Walkthrough_ combining the data.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"YLlU3OvE3dyy","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":446},"outputId":"3d7d5118-e033-41ba-c57b-ead633ff2876","executionInfo":{"status":"ok","timestamp":1541622724831,"user_tz":120,"elapsed":127355,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["# Uploading files from your local file system\n","\n","from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-94dde714-fb6d-4370-ac3f-cb4405510130\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-94dde714-fb6d-4370-ac3f-cb4405510130\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving ap_2010.csv to ap_2010 (3).csv\n","Saving class_size.csv to class_size (3).csv\n","Saving demographics.csv to demographics (3).csv\n","Saving graduation.csv to graduation (3).csv\n","Saving hs_directory.csv to hs_directory (3).csv\n","Saving sat_results.csv to sat_results (3).csv\n","Saving survey_all.txt to survey_all (3).txt\n","Saving survey_d75.txt to survey_d75 (3).txt\n","User uploaded file \"ap_2010.csv\" with length 11993 bytes\n","User uploaded file \"class_size.csv\" with length 2529134 bytes\n","User uploaded file \"demographics.csv\" with length 1588622 bytes\n","User uploaded file \"graduation.csv\" with length 3170974 bytes\n","User uploaded file \"hs_directory.csv\" with length 1343829 bytes\n","User uploaded file \"sat_results.csv\" with length 28818 bytes\n","User uploaded file \"survey_all.txt\" with length 8431567 bytes\n","User uploaded file \"survey_d75.txt\" with length 292057 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"tr-i-yID6z07","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"670317b1-e981-4527-81b2-1df907349c35","executionInfo":{"status":"ok","timestamp":1541630513901,"user_tz":120,"elapsed":859,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["# put your code here\n","\n","import pandas as pd\n","data_files = [\n","    \"ap_2010.csv\",\n","    \"class_size.csv\",\n","    \"demographics.csv\",\n","    \"graduation.csv\",\n","    \"hs_directory.csv\",\n","    \"sat_results.csv\"\n","]\n","data = {}\n","\n","for item in data_files:\n","  d = pd.read_csv(\"{0}\".format(item))\n","  key_name = item.replace(\".csv\",\"\")\n","  data[key_name] = d\n","  print(d.shape)"],"execution_count":106,"outputs":[{"output_type":"stream","text":["(258, 5)\n","(27611, 16)\n","(10075, 38)\n","(25096, 23)\n","(435, 64)\n","(478, 6)\n"],"name":"stdout"}]},{"metadata":{"id":"KdUnIHWz_cRr","colab_type":"code","colab":{}},"cell_type":"code","source":["all_survey = pd.read_csv(\"survey_all.txt\", delimiter=\"\\t\",encoding=\"windows-1252\")\n","d75_survey = pd.read_csv(\"survey_d75.txt\", delimiter=\"\\t\", encoding=\"windows-1252\")\n","survey = pd.concat([all_survey,d75_survey], axis=0)\n","survey[\"DBN\"] = survey[\"dbn\"]\n","columns = [\"DBN\",\"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \n","           \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \n","           \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\",\n","           \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n","survey = survey.loc[:,columns]\n","data[\"survey\"] = survey"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wtGEFD0T_svI","colab_type":"code","colab":{}},"cell_type":"code","source":["def pad_csd(num):\n","    string_representation = str(num)\n","    if len(string_representation) > 1:\n","        return string_representation\n","    else:\n","        return string_representation.zfill(2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lC34GVD8_td3","colab_type":"code","colab":{}},"cell_type":"code","source":["hs_directory = data[\"hs_directory\"]\n","hs_directory[\"DBN\"] = data[\"hs_directory\"].dbn\n","data[\"hs_directory\"] = hs_directory\n","\n","data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n","\n","data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t8sTf7Yw_4sp","colab_type":"code","colab":{}},"cell_type":"code","source":["data[\"sat_results\"][\"SAT Math Avg. Score\"] = pd.to_numeric(data[\"sat_results\"][\"SAT Math Avg. Score\"], errors=\"coerce\")\n","data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"] = pd.to_numeric(data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"], errors=\"coerce\")\n","data[\"sat_results\"][\"SAT Writing Avg. Score\"] = pd.to_numeric(data[\"sat_results\"][\"SAT Writing Avg. Score\"], errors=\"coerce\")\n","\n","data[\"sat_results\"][\"sat_score\"] =  data[\"sat_results\"][\"SAT Math Avg. Score\"] + data[\"sat_results\"][\"SAT Critical Reading Avg. Score\"] + data[\"sat_results\"][\"SAT Writing Avg. Score\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OkgAO0s8_-AC","colab_type":"code","colab":{}},"cell_type":"code","source":["def latitude(string):\n","  import re\n","  coordinates = re.findall(\"\\(.+\\)\", string)\n","  latitude = str(coordinates).split(\",\")[0].replace(\"['(\", \"\")\n","  return latitude\n","\n","def longitude(string):\n","  import re\n","  coordinates = re.findall(\"\\(.+\\)\", string)\n","  longitude = str(coordinates).split(\",\")[1].replace(\")']\", \"\")\n","  return longitude"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S9cVKiLoAOtA","colab_type":"code","colab":{}},"cell_type":"code","source":["data[\"hs_directory\"][\"lat\"] = data[\"hs_directory\"][\"Location 1\"].apply(latitude)\n","\n","data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(longitude)\n","\n","data[\"hs_directory\"][\"lat\"] = pd.to_numeric(data[\"hs_directory\"][\"lat\"], errors=\"coerce\")\n","data[\"hs_directory\"][\"lon\"] = pd.to_numeric(data[\"hs_directory\"][\"lon\"], errors=\"coerce\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Oi0OXsx48yFX","colab_type":"text"},"cell_type":"markdown","source":["# 1.0 Data Cleaning Walkthrough: Combining the Data"]},{"metadata":{"id":"H2CF1nWo8yFZ","colab_type":"text"},"cell_type":"markdown","source":["## 1.1 Introduction"]},{"metadata":{"id":"Z2x3NcmX8yFa","colab_type":"text"},"cell_type":"markdown","source":["In the last mission, we began investigating possible relationships between **SAT scores** and **demographic factors**. In order to do this, we acquired several data sets about [New York City public schools](https://data.cityofnewyork.us/data?cat=education). We manipulated these data sets, and found that we could combine them all using the **DBN** column. All of the data sets are currently stored as **keys** in the **data** dictionary. Each individual data set is a pandas dataframe.\n","\n","In this section, **we'll clean the data a bit more**, then **combine** it. Finally, we'll **compute correlations** and perform some analysis.\n","\n","The first thing we'll need to do in preparation for the merge is condense some of the data sets. In the last section, we noticed that the values in the **DBN** column were unique in the **sat_results** data set. Other data sets like **class_size** had duplicate **DBN** values, however.\n","\n","We'll need to condense these data sets so that each value in the **DBN** column is unique. If not, we'll run into issues when it comes time to combine the data sets.\n","\n","While the main data set we want to analyze, **sat_results**, has unique **DBN** values for every high school in New York City, other data sets aren't as clean. A single row in the **sat_results** data set may match multiple rows in the **class_size** data set, for example. This situation will create problems, because we don't know which of the multiple entries in the **class_size** data set we should combine with the single matching entry in **sat_results**. Here's a diagram that illustrates the problem:\n","\n","\n","<left><img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1deYm5RdQXO2xMX6dUgHLvqDEWipk3axq\"></left>\n","\n","In the diagram above, we can't just combine the rows from both data sets because there are several cases where multiple rows in **class_size** match a single row in **sat_results.**\n","\n","To resolve this issue, we'll condense the **class_size**, **graduation**, and **demographics** data sets so that each **DBN** is unique."]},{"metadata":{"id":"L46dQU968yFb","colab_type":"text"},"cell_type":"markdown","source":["## 1.2 Condensing the Class Size Data Set"]},{"metadata":{"id":"yRCu0U0-8yFc","colab_type":"text"},"cell_type":"markdown","source":["The first data set that we'll condense is **class_size**. The first few rows of **class_size** look like this:\n","\n","|__| CSD | BOROUGH | SCHOOL CODE | SCHOOL NAME               | GRADE | PROGRAM TYPE | CORE SUBJECT (MS CORE and 9-12 ONLY) | CORE COURSE (MS CORE and 9-12 ONLY) | SERVICE CATEGORY(K-9* ONLY) | NUMBER OF STUDENTS / SEATS FILLED | NUMBER OF SECTIONS |\n","|---|-----|---------|-------------|---------------------------|-------|--------------|--------------------------------------|-------------------------------------|-----------------------------|-----------------------------------|--------------------|\n","| 0 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | GEN ED       | -                                    | -                                   | -                           | 19.0                              | 1.0                |\n","| 1 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | CTT          | -                                    | -                                   | -                           | 21.0                              | 1.0                |\n","| 2 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | GEN ED       | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 3 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | CTT          | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 4 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 02    | GEN ED       | -                                    | -                                   | -                           | 15.0                              | 1.0                |\n","\n","As you can see, the first few rows all pertain to the same school, which is why the **DBN** appears more than once. It looks like each school has multiple values for **GRADE**, **PROGRAM TYPE**, **CORE SUBJECT (MS CORE and 9-12 ONLY)**, and **CORE COURSE (MS CORE and 9-12 ONLY)**.\n","\n","If we look at the unique values for **GRADE**, we get the following:\n","\n","```python\n","array(['0K', '01', '02', '03', '04', '05', '0K-09', nan, '06', '07', '08',\n","       'MS Core', '09-12', '09'], dtype=object)\n","```\n","\n","Because we're dealing with high schools, we're only concerned with grades 9 through 12. That means we only want to pick rows where the value in the **GRADE** column is **09-12**.\n","\n","If we look at the unique values for **PROGRAM TYPE**, we get the following:\n","\n","```python\n","array(['GEN ED', 'CTT', 'SPEC ED', nan, 'G&T'], dtype=object)\n","```\n","\n","Each school can have multiple program types. Because **GEN ED** is the largest category by far, let's only select rows where **PROGRAM TYPE** is **GEN ED**.\n","\n"]},{"metadata":{"id":"gL1mmbAK8yFc","colab_type":"text"},"cell_type":"markdown","source":["## 1.3 Condensing the Class Size Data Set"]},{"metadata":{"id":"8Zqa50Z08yFd","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","- Create a new variable called **class_size**, and assign the value of **data[\"class_size\"]** to it.\n","- Filter **class_size** so the **GRADE** column only contains the value **09-12.** Note that the name of the **GRADE** column has a space at the end; you'll generate an error if you don't include it.\n","- Filter **lass_size** so that the **PROGRAM TYPE** column only contains the value **GEN ED.**\n","- Display the first five rows of **class_size** to verify."]},{"metadata":{"id":"8S8Ho7Tz8yFd","colab_type":"code","colab":{}},"cell_type":"code","source":["class_size = data[\"class_size\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JryVVxVn67DK","colab_type":"code","colab":{}},"cell_type":"code","source":["class_size = class_size[class_size[\"GRADE \"] == \"09-12\"]\n","class_size = class_size[class_size[\"PROGRAM TYPE\"] == \"GEN ED\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u8WWJPFU7bw4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":632},"outputId":"ea54af19-db96-4fe7-f246-78feaceb9dbf","executionInfo":{"status":"ok","timestamp":1541630569702,"user_tz":120,"elapsed":799,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["class_size.head()"],"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CSD</th>\n","      <th>BOROUGH</th>\n","      <th>SCHOOL CODE</th>\n","      <th>SCHOOL NAME</th>\n","      <th>GRADE</th>\n","      <th>PROGRAM TYPE</th>\n","      <th>CORE SUBJECT (MS CORE and 9-12 ONLY)</th>\n","      <th>CORE COURSE (MS CORE and 9-12 ONLY)</th>\n","      <th>SERVICE CATEGORY(K-9* ONLY)</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>DATA SOURCE</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","      <th>padded_csd</th>\n","      <th>DBN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>225</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 9</td>\n","      <td>-</td>\n","      <td>63.0</td>\n","      <td>3.0</td>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>25.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>226</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 10</td>\n","      <td>-</td>\n","      <td>79.0</td>\n","      <td>3.0</td>\n","      <td>26.3</td>\n","      <td>24.0</td>\n","      <td>31.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 11</td>\n","      <td>-</td>\n","      <td>38.0</td>\n","      <td>2.0</td>\n","      <td>19.0</td>\n","      <td>16.0</td>\n","      <td>22.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 12</td>\n","      <td>-</td>\n","      <td>69.0</td>\n","      <td>3.0</td>\n","      <td>23.0</td>\n","      <td>13.0</td>\n","      <td>30.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>229</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>MATH</td>\n","      <td>Integrated Algebra</td>\n","      <td>-</td>\n","      <td>53.0</td>\n","      <td>3.0</td>\n","      <td>17.7</td>\n","      <td>16.0</td>\n","      <td>21.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     CSD BOROUGH SCHOOL CODE                                    SCHOOL NAME  \\\n","225    1       M        M292  Henry Street School for International Studies   \n","226    1       M        M292  Henry Street School for International Studies   \n","227    1       M        M292  Henry Street School for International Studies   \n","228    1       M        M292  Henry Street School for International Studies   \n","229    1       M        M292  Henry Street School for International Studies   \n","\n","    GRADE  PROGRAM TYPE CORE SUBJECT (MS CORE and 9-12 ONLY)  \\\n","225  09-12       GEN ED                              ENGLISH   \n","226  09-12       GEN ED                              ENGLISH   \n","227  09-12       GEN ED                              ENGLISH   \n","228  09-12       GEN ED                              ENGLISH   \n","229  09-12       GEN ED                                 MATH   \n","\n","    CORE COURSE (MS CORE and 9-12 ONLY) SERVICE CATEGORY(K-9* ONLY)  \\\n","225                           English 9                           -   \n","226                          English 10                           -   \n","227                          English 11                           -   \n","228                          English 12                           -   \n","229                  Integrated Algebra                           -   \n","\n","     NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n","225                               63.0                 3.0   \n","226                               79.0                 3.0   \n","227                               38.0                 2.0   \n","228                               69.0                 3.0   \n","229                               53.0                 3.0   \n","\n","     AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n","225                21.0                    19.0                   25.0   \n","226                26.3                    24.0                   31.0   \n","227                19.0                    16.0                   22.0   \n","228                23.0                    13.0                   30.0   \n","229                17.7                    16.0                   21.0   \n","\n","    DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO padded_csd     DBN  \n","225       STARS                             NaN         01  01M292  \n","226       STARS                             NaN         01  01M292  \n","227       STARS                             NaN         01  01M292  \n","228       STARS                             NaN         01  01M292  \n","229       STARS                             NaN         01  01M292  "]},"metadata":{"tags":[]},"execution_count":115}]},{"metadata":{"id":"Th72ZVIj8yFf","colab_type":"text"},"cell_type":"markdown","source":["## 1.4 Computing Average Class Sizes"]},{"metadata":{"id":"00ydSvyt8yFg","colab_type":"text"},"cell_type":"markdown","source":["As we saw when we displayed **class_size** on the last screen, **DBN** still isn't completely unique. This is due to the **CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** columns.\n","\n","**CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** seem to pertain to different kinds of classes. For example, here are the unique values for **CORE SUBJECT (MS CORE and 9-12 ONLY)**:\n","\n","```python\n","array(['ENGLISH', 'MATH', 'SCIENCE', 'SOCIAL STUDIES'], dtype=object)\n","```\n","\n","This column only seems to include certain subjects. We want our class size data to include every single class a school offers -- not just a subset of them. What we can do is take the average across all of the classes a school offers. This will give us unique **DBN** values, while also incorporating as much data as possible into the average.\n","\n","Fortunately, we can use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to help us with this. The **DataFrame.groupby()** method will split a dataframe up into unique groups, based on a given column. We can then use the **agg()** method on the resulting **pandas.core.groupby** object to find the **mean** of each column.\n","\n","Let's say we have this data set:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1sJjENlTRR56RwYzBmmsU8aIMELgjx8zg\"></left>\n","\n","Using the **groupby()** method, we'll split this dataframe into four separate groups -- one with the **DBN 01M292**, one with the **DBN 01M332**, one with the **DBN 01M378**, and one with the **DBN 01M448**:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1y9imbMLKRDI50wQqPn7P6TAd6MfCL4Nq\"></left>\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1FitnyClxHDQLnoAB3jR7YI_jEPZZhkco\"></left>\n","\n","Then, we can compute the averages for the **AVERAGE CLASS SIZE** column in each of the four groups using the **agg()** method:\n","\n","<left><img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1gHVZixGOuGYYON_zU0OUPTJcC9Q_mKeV\"></left>\n","\n","After we group a dataframe and aggregate data based on it, the column we performed the grouping on (in this case **DBN**) will become the index, and will no longer appear as a column in the data itself. To undo this change and keep **DBN** as a column, we'll need to use [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html). This method will reset the index to a list of integers and make **DBN** a column again."]},{"metadata":{"id":"mMPOOzjN8yFg","colab_type":"text"},"cell_type":"markdown","source":["## 1.5 Computing Average Class Sizes"]},{"metadata":{"id":"sfdxxqf08yFh","colab_type":"text"},"cell_type":"markdown","source":["- Find the average values for each column associated with each **DBN** in **class_size**.\n","    - Use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to group **class_size** by **DBN**.\n","    - Use the [agg()](http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation) method on the resulting **pandas.core.groupby** object, along with the **numpy.mean()** function as an argument, to calculate the average of each group.\n","    - Assign the result back to **class_size**.\n","- Reset the index to make **DBN** a column again.\n","    - Use the [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html) method, along with the keyword argument **inplace=True**.\n","- Assign **class_size** back to the **class_size** key of the **data** dictionary.\n","- Display the first few rows of **data[\"class_size\"]** to verify that everything went okay."]},{"metadata":{"id":"xGKLTHOi8yFi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"f048022a-3712-4f33-8b42-a1eabc213d1a","executionInfo":{"status":"ok","timestamp":1541630663329,"user_tz":120,"elapsed":596,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["import numpy as np\n","class_size = class_size.groupby(\"DBN\").agg(np.mean)\n","class_size.reset_index(inplace=True)\n","data[\"class_size\"] = class_size\n","data[\"class_size\"].head()"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>CSD</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>1</td>\n","      <td>88.0000</td>\n","      <td>4.000000</td>\n","      <td>22.564286</td>\n","      <td>18.50</td>\n","      <td>26.571429</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M332</td>\n","      <td>1</td>\n","      <td>46.0000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>21.00</td>\n","      <td>23.500000</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M378</td>\n","      <td>1</td>\n","      <td>33.0000</td>\n","      <td>1.000000</td>\n","      <td>33.000000</td>\n","      <td>33.00</td>\n","      <td>33.000000</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M448</td>\n","      <td>1</td>\n","      <td>105.6875</td>\n","      <td>4.750000</td>\n","      <td>22.231250</td>\n","      <td>18.25</td>\n","      <td>27.062500</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M450</td>\n","      <td>1</td>\n","      <td>57.6000</td>\n","      <td>2.733333</td>\n","      <td>21.200000</td>\n","      <td>19.40</td>\n","      <td>22.866667</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      DBN  CSD  NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n","0  01M292    1                            88.0000            4.000000   \n","1  01M332    1                            46.0000            2.000000   \n","2  01M378    1                            33.0000            1.000000   \n","3  01M448    1                           105.6875            4.750000   \n","4  01M450    1                            57.6000            2.733333   \n","\n","   AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n","0           22.564286                   18.50              26.571429   \n","1           22.000000                   21.00              23.500000   \n","2           33.000000                   33.00              33.000000   \n","3           22.231250                   18.25              27.062500   \n","4           21.200000                   19.40              22.866667   \n","\n","   SCHOOLWIDE PUPIL-TEACHER RATIO  \n","0                             NaN  \n","1                             NaN  \n","2                             NaN  \n","3                             NaN  \n","4                             NaN  "]},"metadata":{"tags":[]},"execution_count":116}]},{"metadata":{"id":"f2I6dT0KAoED","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"W4XtGPNh8yFl","colab_type":"text"},"cell_type":"markdown","source":["## 1.6 Condensing the Demographics Data Set"]},{"metadata":{"id":"ijDhJZeb8yFl","colab_type":"text"},"cell_type":"markdown","source":["Now that we've finished condensing **class_size**, let's condense **demographics**. The first few rows look like this:\n","\n","| _| DBN    | Name                      | schoolyear | fl_percent | frl_percent | total_enrollment | prek | k  | grade1 | grade2 |\n","|---|--------|---------------------------|------------|------------|-------------|------------------|------|----|--------|--------|\n","| 0 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20052006   | 89.4       | NaN         | 281              | 15   | 36 | 40     | 33     |\n","| 1 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20062007   | 89.4       | NaN         | 243              | 15   | 29 | 39     | 38     |\n","| 2 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20072008   | 89.4       | NaN         | 261              | 18   | 43 | 39     | 36     |\n","| 3 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20082009   | 89.4       | NaN         | 252              | 17   | 37 | 44     | 32     |\n","| 4 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20092010   |  _          | 96.5        | 208              | 16   | 40 | 28     | 32     |\n","\n","In this case, the only column that prevents a given **DBN** from being unique is **schoolyear**. We only want to select rows where schoolyear is **20112012**. This will give us the most recent year of data, and also match our SAT results data."]},{"metadata":{"id":"VnDEAeuB8yFn","colab_type":"text"},"cell_type":"markdown","source":["## 1.7 Condensing the Demographics Data Set"]},{"metadata":{"id":"C5g2PiJt8yFn","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **demographics**, only selecting rows in **data[\"demographics\"]** where **schoolyear** is **20112012.**\n","    - **schoolyear** is actually an integer, so be careful about how you perform your comparison.\n","- Display the first few rows of **data[\"demographics\"]** to verify that the filtering worked."]},{"metadata":{"id":"4QUcmKI28yFo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"fab0a616-ce39-4b03-a6dc-81ce161c0e29","executionInfo":{"status":"ok","timestamp":1541630673271,"user_tz":120,"elapsed":571,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["demographics = data[\"demographics\"]\n","demographics = demographics[demographics[\"schoolyear\"] == 20112012]\n","demographics.reset_index(inplace=True)\n","data[\"demographics\"] = demographics\n","data[\"demographics\"].head()"],"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>DBN</th>\n","      <th>Name</th>\n","      <th>schoolyear</th>\n","      <th>fl_percent</th>\n","      <th>frl_percent</th>\n","      <th>total_enrollment</th>\n","      <th>prek</th>\n","      <th>k</th>\n","      <th>grade1</th>\n","      <th>...</th>\n","      <th>black_num</th>\n","      <th>black_per</th>\n","      <th>hispanic_num</th>\n","      <th>hispanic_per</th>\n","      <th>white_num</th>\n","      <th>white_per</th>\n","      <th>male_num</th>\n","      <th>male_per</th>\n","      <th>female_num</th>\n","      <th>female_per</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>01M015</td>\n","      <td>P.S. 015 ROBERTO CLEMENTE</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>89.4</td>\n","      <td>189</td>\n","      <td>13</td>\n","      <td>31</td>\n","      <td>35</td>\n","      <td>...</td>\n","      <td>63</td>\n","      <td>33.3</td>\n","      <td>109</td>\n","      <td>57.7</td>\n","      <td>4</td>\n","      <td>2.1</td>\n","      <td>97.0</td>\n","      <td>51.3</td>\n","      <td>92.0</td>\n","      <td>48.7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13</td>\n","      <td>01M019</td>\n","      <td>P.S. 019 ASHER LEVY</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>61.5</td>\n","      <td>328</td>\n","      <td>32</td>\n","      <td>46</td>\n","      <td>52</td>\n","      <td>...</td>\n","      <td>81</td>\n","      <td>24.7</td>\n","      <td>158</td>\n","      <td>48.2</td>\n","      <td>28</td>\n","      <td>8.5</td>\n","      <td>147.0</td>\n","      <td>44.8</td>\n","      <td>181.0</td>\n","      <td>55.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20</td>\n","      <td>01M020</td>\n","      <td>PS 020 ANNA SILVER</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>92.5</td>\n","      <td>626</td>\n","      <td>52</td>\n","      <td>102</td>\n","      <td>121</td>\n","      <td>...</td>\n","      <td>55</td>\n","      <td>8.8</td>\n","      <td>357</td>\n","      <td>57.0</td>\n","      <td>16</td>\n","      <td>2.6</td>\n","      <td>330.0</td>\n","      <td>52.7</td>\n","      <td>296.0</td>\n","      <td>47.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>01M034</td>\n","      <td>PS 034 FRANKLIN D ROOSEVELT</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>99.7</td>\n","      <td>401</td>\n","      <td>14</td>\n","      <td>34</td>\n","      <td>38</td>\n","      <td>...</td>\n","      <td>90</td>\n","      <td>22.4</td>\n","      <td>275</td>\n","      <td>68.6</td>\n","      <td>8</td>\n","      <td>2.0</td>\n","      <td>204.0</td>\n","      <td>50.9</td>\n","      <td>197.0</td>\n","      <td>49.1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>35</td>\n","      <td>01M063</td>\n","      <td>PS 063 WILLIAM MCKINLEY</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>78.9</td>\n","      <td>176</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>...</td>\n","      <td>41</td>\n","      <td>23.3</td>\n","      <td>110</td>\n","      <td>62.5</td>\n","      <td>15</td>\n","      <td>8.5</td>\n","      <td>97.0</td>\n","      <td>55.1</td>\n","      <td>79.0</td>\n","      <td>44.9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 39 columns</p>\n","</div>"],"text/plain":["   index     DBN                                              Name  \\\n","0      6  01M015  P.S. 015 ROBERTO CLEMENTE                          \n","1     13  01M019  P.S. 019 ASHER LEVY                                \n","2     20  01M020  PS 020 ANNA SILVER                                 \n","3     27  01M034  PS 034 FRANKLIN D ROOSEVELT                        \n","4     35  01M063  PS 063 WILLIAM MCKINLEY                            \n","\n","   schoolyear fl_percent  frl_percent  total_enrollment prek    k grade1  \\\n","0    20112012        NaN         89.4               189   13   31     35   \n","1    20112012        NaN         61.5               328   32   46     52   \n","2    20112012        NaN         92.5               626   52  102    121   \n","3    20112012        NaN         99.7               401   14   34     38   \n","4    20112012        NaN         78.9               176   18   20     30   \n","\n","     ...     black_num black_per hispanic_num hispanic_per white_num  \\\n","0    ...            63      33.3          109         57.7         4   \n","1    ...            81      24.7          158         48.2        28   \n","2    ...            55       8.8          357         57.0        16   \n","3    ...            90      22.4          275         68.6         8   \n","4    ...            41      23.3          110         62.5        15   \n","\n","  white_per male_num male_per female_num female_per  \n","0       2.1     97.0     51.3       92.0       48.7  \n","1       8.5    147.0     44.8      181.0       55.2  \n","2       2.6    330.0     52.7      296.0       47.3  \n","3       2.0    204.0     50.9      197.0       49.1  \n","4       8.5     97.0     55.1       79.0       44.9  \n","\n","[5 rows x 39 columns]"]},"metadata":{"tags":[]},"execution_count":117}]},{"metadata":{"id":"x5dkSi8s8yFs","colab_type":"text"},"cell_type":"markdown","source":["## 1.8 Condensing the Graduation Data Set"]},{"metadata":{"id":"5xQzgi_Q8yFs","colab_type":"text"},"cell_type":"markdown","source":["Finally, we'll need to condense the **graduation** data set. Here are the first few rows:\n","\n","| _ | Demographic  | DBN    | School Name                           | Cohort   | Total Cohort | Total Grads - n |\n","|---|--------------|--------|---------------------------------------|----------|--------------|-----------------|\n","| 0 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2003     | 5            | s               |\n","| 1 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2004     | 55           | 37              |\n","| 2 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2005     | 64           | 43              |\n","| 3 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006     | 78           | 43              |\n","| 4 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006 Aug | 78           | 44              |\n","\n","The **Demographic** and **Cohort** columns are what prevent **DBN** from being unique in the **graduation** data. A **Cohort** appears to refer to the year the data represents, and the **Demographic** appears to refer to a specific demographic group. In this case, we want to pick data from the most recent Cohort available, which is 2006. We also want data from the full cohort, so we'll only pick rows where **Demographic** is **Total Cohort**."]},{"metadata":{"id":"IIHasD3G8yFt","colab_type":"text"},"cell_type":"markdown","source":["## 1.9 Condensing the Graduation Data Set"]},{"metadata":{"id":"7m8fZlxr8yFv","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **graduation**, only selecting rows where the **Cohort** column equals **2006.**\n","- Filter **graduation**, only selecting rows where the **Demographic** column equals **Total Cohort**.\n","- Display the first few rows of **data[\"graduation\"]** to verify that everything worked properly."]},{"metadata":{"id":"JjMUikQu8yFv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":491},"outputId":"5d36a712-17f0-4932-d0ca-112854615ad4","executionInfo":{"status":"ok","timestamp":1541630681202,"user_tz":120,"elapsed":613,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["graduation = data[\"graduation\"]\n","graduation = graduation[graduation[\"Cohort\"] == \"2006\"]\n","graduation = graduation[graduation[\"Demographic\"] == \"Total Cohort\"]\n","graduation.reset_index(inplace=True)\n","data[\"graduation\"] = graduation\n","data[\"graduation\"].head()"],"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Demographic</th>\n","      <th>DBN</th>\n","      <th>School Name</th>\n","      <th>Cohort</th>\n","      <th>Total Cohort</th>\n","      <th>Total Grads - n</th>\n","      <th>Total Grads - % of cohort</th>\n","      <th>Total Regents - n</th>\n","      <th>Total Regents - % of cohort</th>\n","      <th>...</th>\n","      <th>Regents w/o Advanced - n</th>\n","      <th>Regents w/o Advanced - % of cohort</th>\n","      <th>Regents w/o Advanced - % of grads</th>\n","      <th>Local - n</th>\n","      <th>Local - % of cohort</th>\n","      <th>Local - % of grads</th>\n","      <th>Still Enrolled - n</th>\n","      <th>Still Enrolled - % of cohort</th>\n","      <th>Dropped Out - n</th>\n","      <th>Dropped Out - % of cohort</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>Total Cohort</td>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL</td>\n","      <td>2006</td>\n","      <td>78</td>\n","      <td>43</td>\n","      <td>55.1</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>...</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>83.7</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>16.3</td>\n","      <td>16</td>\n","      <td>20.5</td>\n","      <td>11</td>\n","      <td>14.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10</td>\n","      <td>Total Cohort</td>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>124</td>\n","      <td>53</td>\n","      <td>42.7</td>\n","      <td>42</td>\n","      <td>33.9</td>\n","      <td>...</td>\n","      <td>34</td>\n","      <td>27.4</td>\n","      <td>64.2</td>\n","      <td>11</td>\n","      <td>8.9</td>\n","      <td>20.8</td>\n","      <td>46</td>\n","      <td>37.1</td>\n","      <td>20</td>\n","      <td>16.100000000000001</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>17</td>\n","      <td>Total Cohort</td>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>2006</td>\n","      <td>90</td>\n","      <td>70</td>\n","      <td>77.8</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>...</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>95.7</td>\n","      <td>3</td>\n","      <td>3.3</td>\n","      <td>4.3</td>\n","      <td>15</td>\n","      <td>16.7</td>\n","      <td>5</td>\n","      <td>5.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>24</td>\n","      <td>Total Cohort</td>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>56</td>\n","      <td>40</td>\n","      <td>47.6</td>\n","      <td>...</td>\n","      <td>23</td>\n","      <td>27.4</td>\n","      <td>48.9</td>\n","      <td>7</td>\n","      <td>8.300000000000001</td>\n","      <td>14.9</td>\n","      <td>25</td>\n","      <td>29.8</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31</td>\n","      <td>Total Cohort</td>\n","      <td>01M515</td>\n","      <td>LOWER EAST SIDE PREPARATORY HIGH SCHO</td>\n","      <td>2006</td>\n","      <td>193</td>\n","      <td>105</td>\n","      <td>54.4</td>\n","      <td>91</td>\n","      <td>47.2</td>\n","      <td>...</td>\n","      <td>22</td>\n","      <td>11.4</td>\n","      <td>21</td>\n","      <td>14</td>\n","      <td>7.3</td>\n","      <td>13.3</td>\n","      <td>53</td>\n","      <td>27.5</td>\n","      <td>35</td>\n","      <td>18.100000000000001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>"],"text/plain":["   index   Demographic     DBN                            School Name Cohort  \\\n","0      3  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL   2006   \n","1     10  Total Cohort  01M448    UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   2006   \n","2     17  Total Cohort  01M450             EAST SIDE COMMUNITY SCHOOL   2006   \n","3     24  Total Cohort  01M509                MARTA VALLE HIGH SCHOOL   2006   \n","4     31  Total Cohort  01M515  LOWER EAST SIDE PREPARATORY HIGH SCHO   2006   \n","\n","   Total Cohort Total Grads - n Total Grads - % of cohort Total Regents - n  \\\n","0            78              43                      55.1                36   \n","1           124              53                      42.7                42   \n","2            90              70                      77.8                67   \n","3            84              47                        56                40   \n","4           193             105                      54.4                91   \n","\n","  Total Regents - % of cohort            ...             \\\n","0                        46.2            ...              \n","1                        33.9            ...              \n","2          74.400000000000006            ...              \n","3                        47.6            ...              \n","4                        47.2            ...              \n","\n","  Regents w/o Advanced - n Regents w/o Advanced - % of cohort  \\\n","0                       36                               46.2   \n","1                       34                               27.4   \n","2                       67                 74.400000000000006   \n","3                       23                               27.4   \n","4                       22                               11.4   \n","\n","  Regents w/o Advanced - % of grads Local - n Local - % of cohort  \\\n","0                              83.7         7                   9   \n","1                              64.2        11                 8.9   \n","2                              95.7         3                 3.3   \n","3                              48.9         7   8.300000000000001   \n","4                                21        14                 7.3   \n","\n","  Local - % of grads Still Enrolled - n Still Enrolled - % of cohort  \\\n","0               16.3                 16                         20.5   \n","1               20.8                 46                         37.1   \n","2                4.3                 15                         16.7   \n","3               14.9                 25                         29.8   \n","4               13.3                 53                         27.5   \n","\n","  Dropped Out - n Dropped Out - % of cohort  \n","0              11                      14.1  \n","1              20        16.100000000000001  \n","2               5                       5.6  \n","3               5                         6  \n","4              35        18.100000000000001  \n","\n","[5 rows x 24 columns]"]},"metadata":{"tags":[]},"execution_count":118}]},{"metadata":{"id":"ak0EfoSm8yFy","colab_type":"text"},"cell_type":"markdown","source":["## 1.10 Converting AP Test Scores"]},{"metadata":{"id":"DMmk__7t8yFy","colab_type":"text"},"cell_type":"markdown","source":["We're almost ready to combine all of the data sets. The only remaining thing to do is convert the [Advanced Placement (AP)](https://en.wikipedia.org/wiki/Advanced_Placement_exams) test scores from strings to numeric values. High school students take the AP exams before applying to college. There are several AP exams, each corresponding to a school subject. High school students who earn high scores may receive college credit.\n","\n","AP exams have a 1 to 5 scale; 3 or higher is a passing score. Many high school students take AP exams -- particularly those who attend academically challenging institutions. AP exams are much more rare in schools that lack funding or academic rigor.\n","\n","It will be interesting to find out whether AP exam scores are correlated with SAT scores across high schools. To determine this, we'll need to convert the AP exam scores in the **ap_2010** data set to numeric values first.\n","\n","There are three columns we'll need to convert:\n","\n","- **AP Test Takers** (note that there's a trailing space in the column name)\n","- **Total Exams Taken**\n","- **Number of Exams with scores 3 4 or 5**\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Convert each of the following columns in **ap_2010** to numeric values using the [pandas.to_numeric()](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.to_numeric.html) function with the keyword argument **errors=\"coerce\".**\n","    - **AP Test Takers**\n","    - **Total Exams Taken**\n","    - **Number of Exams with scores 3 4 or 5**\n","- Display the column types using the **dtypes** attribute."]},{"metadata":{"id":"_qW0QDiM8yFz","colab_type":"code","colab":{}},"cell_type":"code","source":["data[\"ap_2010\"][\"AP Test Takers \"] = pd.to_numeric(data[\"ap_2010\"][\"AP Test Takers \"], errors=\"coerce\")\n","data[\"ap_2010\"][\"Total Exams Taken\"] = pd.to_numeric(data[\"ap_2010\"][\"Total Exams Taken\"], errors=\"coerce\")\n","data[\"ap_2010\"][\"Number of Exams with scores 3 4 or 5\"] = pd.to_numeric(data[\"ap_2010\"][\"Number of Exams with scores 3 4 or 5\"], errors=\"coerce\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qE-uOfnrPTOZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"19c55cff-b3e9-4d75-90c8-cff294473ace","executionInfo":{"status":"ok","timestamp":1541630689899,"user_tz":120,"elapsed":563,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["print(data[\"ap_2010\"].dtypes)"],"execution_count":120,"outputs":[{"output_type":"stream","text":["DBN                                      object\n","SchoolName                               object\n","AP Test Takers                          float64\n","Total Exams Taken                       float64\n","Number of Exams with scores 3 4 or 5    float64\n","dtype: object\n"],"name":"stdout"}]},{"metadata":{"id":"8sB0lAzH8yF0","colab_type":"text"},"cell_type":"markdown","source":["## 1.11 Left, Right, Inner, and Outer Joins"]},{"metadata":{"id":"Vjm8aBE68yF1","colab_type":"text"},"cell_type":"markdown","source":["Before we merge our data, we'll need to decide on the merge strategy we want to use. We'll be using the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) function, which supports four types of joins -- **left**, **right**, **inner**, and **outer**. Each of these join types dictates how pandas combines the rows.\n","\n","We'll be using the **DBN** column to identify matching rows across data sets. In other words, the values in that column will help us know which row from the first data set to combine with which row in the second data set.\n","\n","There may be **DBN** values that exist in one data set but not in another. This is partly because the data is from different years. Each data set also has inconsistencies in terms of how it was gathered. Human error (and other types of errors) may also play a role. Therefore, we may not find matches for the **DBN** values in **sat_results** in all of the other data sets, and other data sets may have **DBN** values that don't exist in **sat_results**.\n","\n","We'll merge two data sets at a time. For example, we'll merge **sat_results** and **hs_directory**, then merge the result with **ap_2010**, then merge the result of that with **class_size**. We'll continue combining data sets in this way until we've merged all of them. Afterwards, we'll have roughly the same number of rows, but each row will have columns from all of the data sets.\n","\n","The merge strategy we pick will affect the number of rows we end up with. Let's take a look at each strategy.\n","\n","Let's say we're merging the following two data sets:\n","\n","<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Vlypix_SIkxCdRS0ABvO4tGiuvFLg321\"></left>\n","\n","With an **inner merge**, we'd only combine rows where the same **DBN** exists in both data sets. We'd end up with this result:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1LR4c8louX-JAZFYta_Y99FLsGkCf9grr\"></left>\n","\n","With a **left merge**, we'd only use **DBN** values from the dataframe on the \"left\" of the merge. In this case, **sat_results** is on the left. Some of the DBNs in **sat_results** don't exist in **class_size**, though. The merge will handle this by assiging null values to the columns in **sat_results** that don't have corresponding data in **class_size.**\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1hPoJ5wLECEzz25jrTP5bw9oZ0eerNi2p\"></left>\n","\n","With a **right merge**, we'll only use **DBN** values from the dataframe on the \"right\" of the merge. In this case, **class_size** is on the right:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1YYdf4iEMtHYqRBMTEFcfuTyu9zdFlnx7\"></left>\n","\n","With an outer merge, we'll take any DBN values from either sat_results or class_size:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1sl5wCK3WZ3lTzJm8JUn-bg4MoXl3xSe9\"></left>\n","\n","As you can see, each merge strategy has its advantages. Depending on the strategy we choose, we may preserve rows at the expense of having more missing column data, or minimize missing data at the expense of having fewer rows. Choosing a merge strategy is an important decision; it's worth thinking about your data carefully, and what trade-offs you're willing to make.\n","\n","Because this project is concerned with determing demographic factors that correlate with SAT score, we'll want to preserve as many rows as possible from **sat_results** while minimizing null values.\n","\n","This means that we may need to use different merge strategies with different data sets. Some of the data sets have a lot of missing **DBN** values. This makes a **left** join more appropriate, because we don't want to lose too many rows when we merge. If we did an **inner** join, we would lose the data for many high schools.\n","\n","Some data sets have **DBN** values that are almost identical to those in **sat_results**. Those data sets also have information we need to keep. Most of our analysis would be impossible if a significant number of rows was missing from **demographics**, for example. Therefore, we'll do an inner join to avoid missing data in these columns."]},{"metadata":{"id":"XpPfMAwI8yF1","colab_type":"text"},"cell_type":"markdown","source":["##  1.12 Performing the Left Joins"]},{"metadata":{"id":"TC5oEhTL8yF2","colab_type":"text"},"cell_type":"markdown","source":["Both the **ap_2010** and the **graduation** data sets have many missing **DBN** values, so we'll use a left join when we merge the **sat_results** data set with them. Because we're using a **left** join, our final dataframe will have all of the same **DBN** values as the original **sat_results** dataframe.\n","\n","We'll need to use the pandas **df.merge()** method to merge dataframes. The \"left\" dataframe is the one we call the method on, and the \"right\" dataframe is the one we pass into **df.merge()**.\n","\n","Because we're using the **DBN** column to join the dataframes, we'll need to specify the keyword argument **on=\"DBN\"** when calling **pandas.DataFrame.merge().**\n","\n","First, we'll assign **data[\"sat_results\"]** to the variable **combined**. Then, we'll merge all of the other dataframes with **combined**. When we're finished, **combined** will have all of the columns from all of the data sets.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Use the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) method to merge the **ap_2010** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to indicate the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Use the pandas **df.merge()** method to merge the **graduation** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to get the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Use the [pandas.DataFrame.shape](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.shape.html) attribute to display the shape of the dataframe and see how many rows now exist."]},{"metadata":{"id":"06arIDoX8yF3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":491},"outputId":"0e71e958-cc29-404e-ecd2-d28b4d44baa8","executionInfo":{"status":"ok","timestamp":1541630695503,"user_tz":120,"elapsed":561,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["combined = data[\"sat_results\"]\n","combined = combined.merge(data[\"ap_2010\"], on=\"DBN\",how=\"left\")\n","combined = combined.merge(data[\"graduation\"], on=\"DBN\", how=\"left\")\n","combined.head()"],"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>SCHOOL NAME</th>\n","      <th>Num of SAT Test Takers</th>\n","      <th>SAT Critical Reading Avg. Score</th>\n","      <th>SAT Math Avg. Score</th>\n","      <th>SAT Writing Avg. Score</th>\n","      <th>sat_score</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>...</th>\n","      <th>Regents w/o Advanced - n</th>\n","      <th>Regents w/o Advanced - % of cohort</th>\n","      <th>Regents w/o Advanced - % of grads</th>\n","      <th>Local - n</th>\n","      <th>Local - % of cohort</th>\n","      <th>Local - % of grads</th>\n","      <th>Still Enrolled - n</th>\n","      <th>Still Enrolled - % of cohort</th>\n","      <th>Dropped Out - n</th>\n","      <th>Dropped Out - % of cohort</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n","      <td>29</td>\n","      <td>355.0</td>\n","      <td>404.0</td>\n","      <td>363.0</td>\n","      <td>1122.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>83.7</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>16.3</td>\n","      <td>16</td>\n","      <td>20.5</td>\n","      <td>11</td>\n","      <td>14.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>91</td>\n","      <td>383.0</td>\n","      <td>423.0</td>\n","      <td>366.0</td>\n","      <td>1172.0</td>\n","      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n","      <td>39.0</td>\n","      <td>49.0</td>\n","      <td>...</td>\n","      <td>34</td>\n","      <td>27.4</td>\n","      <td>64.2</td>\n","      <td>11</td>\n","      <td>8.9</td>\n","      <td>20.8</td>\n","      <td>46</td>\n","      <td>37.1</td>\n","      <td>20</td>\n","      <td>16.100000000000001</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>70</td>\n","      <td>377.0</td>\n","      <td>402.0</td>\n","      <td>370.0</td>\n","      <td>1149.0</td>\n","      <td>EAST SIDE COMMUNITY HS</td>\n","      <td>19.0</td>\n","      <td>21.0</td>\n","      <td>...</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>95.7</td>\n","      <td>3</td>\n","      <td>3.3</td>\n","      <td>4.3</td>\n","      <td>15</td>\n","      <td>16.7</td>\n","      <td>5</td>\n","      <td>5.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M458</td>\n","      <td>FORSYTH SATELLITE ACADEMY</td>\n","      <td>7</td>\n","      <td>414.0</td>\n","      <td>401.0</td>\n","      <td>359.0</td>\n","      <td>1174.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>44</td>\n","      <td>390.0</td>\n","      <td>433.0</td>\n","      <td>384.0</td>\n","      <td>1207.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>23</td>\n","      <td>27.4</td>\n","      <td>48.9</td>\n","      <td>7</td>\n","      <td>8.300000000000001</td>\n","      <td>14.9</td>\n","      <td>25</td>\n","      <td>29.8</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>"],"text/plain":["      DBN                                    SCHOOL NAME  \\\n","0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n","1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n","2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n","3  01M458                      FORSYTH SATELLITE ACADEMY   \n","4  01M509                        MARTA VALLE HIGH SCHOOL   \n","\n","  Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n","0                     29                            355.0   \n","1                     91                            383.0   \n","2                     70                            377.0   \n","3                      7                            414.0   \n","4                     44                            390.0   \n","\n","   SAT Math Avg. Score  SAT Writing Avg. Score  sat_score  \\\n","0                404.0                   363.0     1122.0   \n","1                423.0                   366.0     1172.0   \n","2                402.0                   370.0     1149.0   \n","3                401.0                   359.0     1174.0   \n","4                433.0                   384.0     1207.0   \n","\n","                     SchoolName  AP Test Takers   Total Exams Taken  \\\n","0                           NaN              NaN                NaN   \n","1  UNIVERSITY NEIGHBORHOOD H.S.             39.0               49.0   \n","2        EAST SIDE COMMUNITY HS             19.0               21.0   \n","3                           NaN              NaN                NaN   \n","4                           NaN              NaN                NaN   \n","\n","             ...             Regents w/o Advanced - n  \\\n","0            ...                                   36   \n","1            ...                                   34   \n","2            ...                                   67   \n","3            ...                                  NaN   \n","4            ...                                   23   \n","\n","   Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n","0                                46.2                              83.7   \n","1                                27.4                              64.2   \n","2                  74.400000000000006                              95.7   \n","3                                 NaN                               NaN   \n","4                                27.4                              48.9   \n","\n","  Local - n Local - % of cohort  Local - % of grads Still Enrolled - n  \\\n","0         7                   9                16.3                 16   \n","1        11                 8.9                20.8                 46   \n","2         3                 3.3                 4.3                 15   \n","3       NaN                 NaN                 NaN                NaN   \n","4         7   8.300000000000001                14.9                 25   \n","\n","  Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n","0                         20.5              11                      14.1  \n","1                         37.1              20        16.100000000000001  \n","2                         16.7               5                       5.6  \n","3                          NaN             NaN                       NaN  \n","4                         29.8               5                         6  \n","\n","[5 rows x 34 columns]"]},"metadata":{"tags":[]},"execution_count":121}]},{"metadata":{"id":"-MMR7ZQMQXpU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1d365cf0-5c96-4381-b10d-5001b682dc52","executionInfo":{"status":"ok","timestamp":1541630700872,"user_tz":120,"elapsed":560,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["combined.shape"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(479, 34)"]},"metadata":{"tags":[]},"execution_count":122}]},{"metadata":{"id":"VMMJAmet8yF6","colab_type":"text"},"cell_type":"markdown","source":["## 1.13 Performing the Inner Joins"]},{"metadata":{"id":"Nn8-wD4k8yF7","colab_type":"text"},"cell_type":"markdown","source":["Now that we've performed the left joins, we still have to merge **class_size**, **demographics**, **survey**, and **hs_directory** into **combined**. Because these files contain information that's more valuable to our analysis and also have fewer missing **DBN** values, we'll use the **inner** join type.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Merge **class_size** into **combined**. Then, merge **demographics**, **survey**, and **hs_directory** into **combined** one by one, in that order.\n","    - Be sure to follow the exact order above.\n","    - Remember to specify the correct column to join on, as well as the correct join type.\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Call **pandas.DataFrame.shape()** to display the shape of the dataframe to see how many rows now exist."]},{"metadata":{"id":"xEbfC4f58yF8","colab_type":"code","colab":{}},"cell_type":"code","source":["combined = combined.merge(data[\"class_size\"], on=\"DBN\", how=\"inner\")\n","combined = combined.merge(data[\"demographics\"], on=\"DBN\", how=\"inner\")\n","combined = combined.merge(data[\"survey\"], on=\"DBN\", how=\"inner\")\n","combined = combined.merge(data[\"hs_directory\"], on=\"DBN\", how=\"inner\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sMXrILOoWfQj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":593},"outputId":"685eb335-776b-4bd3-ecdf-bb9c1a6e3741","executionInfo":{"status":"ok","timestamp":1541630751911,"user_tz":120,"elapsed":628,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["combined.head()"],"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>SCHOOL NAME</th>\n","      <th>Num of SAT Test Takers</th>\n","      <th>SAT Critical Reading Avg. Score</th>\n","      <th>SAT Math Avg. Score</th>\n","      <th>SAT Writing Avg. Score</th>\n","      <th>sat_score</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>...</th>\n","      <th>priority10</th>\n","      <th>Location 1</th>\n","      <th>Community Board</th>\n","      <th>Council District</th>\n","      <th>Census Tract</th>\n","      <th>BIN</th>\n","      <th>BBL</th>\n","      <th>NTA</th>\n","      <th>lat</th>\n","      <th>lon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n","      <td>29</td>\n","      <td>355.0</td>\n","      <td>404.0</td>\n","      <td>363.0</td>\n","      <td>1122.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>220 Henry Street\\nNew York, NY 10002\\n(40.7137...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>201.0</td>\n","      <td>1003223.0</td>\n","      <td>1.002690e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.713764</td>\n","      <td>-73.985260</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>91</td>\n","      <td>383.0</td>\n","      <td>423.0</td>\n","      <td>366.0</td>\n","      <td>1172.0</td>\n","      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n","      <td>39.0</td>\n","      <td>49.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>200 Monroe Street\\nNew York, NY 10002\\n(40.712...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>202.0</td>\n","      <td>1003214.0</td>\n","      <td>1.002590e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.712332</td>\n","      <td>-73.984797</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>70</td>\n","      <td>377.0</td>\n","      <td>402.0</td>\n","      <td>370.0</td>\n","      <td>1149.0</td>\n","      <td>EAST SIDE COMMUNITY HS</td>\n","      <td>19.0</td>\n","      <td>21.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>420 East 12 Street\\nNew York, NY 10009\\n(40.72...</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>34.0</td>\n","      <td>1005974.0</td>\n","      <td>1.004390e+09</td>\n","      <td>East Village                                  ...</td>\n","      <td>40.729783</td>\n","      <td>-73.983041</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>44</td>\n","      <td>390.0</td>\n","      <td>433.0</td>\n","      <td>384.0</td>\n","      <td>1207.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>145 Stanton Street\\nNew York, NY 10002\\n(40.72...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3001.0</td>\n","      <td>1004323.0</td>\n","      <td>1.003540e+09</td>\n","      <td>Chinatown                                     ...</td>\n","      <td>40.720569</td>\n","      <td>-73.985673</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M539</td>\n","      <td>NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...</td>\n","      <td>159</td>\n","      <td>522.0</td>\n","      <td>574.0</td>\n","      <td>525.0</td>\n","      <td>1621.0</td>\n","      <td>NEW EXPLORATIONS SCI,TECH,MATH</td>\n","      <td>255.0</td>\n","      <td>377.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>111 Columbia Street\\nNew York, NY 10002\\n(40.7...</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2201.0</td>\n","      <td>1004070.0</td>\n","      <td>1.003350e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.718725</td>\n","      <td>-73.979426</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 167 columns</p>\n","</div>"],"text/plain":["      DBN                                        SCHOOL NAME  \\\n","0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n","1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n","2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n","3  01M509                            MARTA VALLE HIGH SCHOOL   \n","4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n","\n","  Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n","0                     29                            355.0   \n","1                     91                            383.0   \n","2                     70                            377.0   \n","3                     44                            390.0   \n","4                    159                            522.0   \n","\n","   SAT Math Avg. Score  SAT Writing Avg. Score  sat_score  \\\n","0                404.0                   363.0     1122.0   \n","1                423.0                   366.0     1172.0   \n","2                402.0                   370.0     1149.0   \n","3                433.0                   384.0     1207.0   \n","4                574.0                   525.0     1621.0   \n","\n","                       SchoolName  AP Test Takers   Total Exams Taken  \\\n","0                             NaN              NaN                NaN   \n","1    UNIVERSITY NEIGHBORHOOD H.S.             39.0               49.0   \n","2          EAST SIDE COMMUNITY HS             19.0               21.0   \n","3                             NaN              NaN                NaN   \n","4  NEW EXPLORATIONS SCI,TECH,MATH            255.0              377.0   \n","\n","     ...      priority10                                         Location 1  \\\n","0    ...             NaN  220 Henry Street\\nNew York, NY 10002\\n(40.7137...   \n","1    ...             NaN  200 Monroe Street\\nNew York, NY 10002\\n(40.712...   \n","2    ...             NaN  420 East 12 Street\\nNew York, NY 10009\\n(40.72...   \n","3    ...             NaN  145 Stanton Street\\nNew York, NY 10002\\n(40.72...   \n","4    ...             NaN  111 Columbia Street\\nNew York, NY 10002\\n(40.7...   \n","\n","  Community Board Council District Census Tract        BIN           BBL  \\\n","0             3.0              1.0        201.0  1003223.0  1.002690e+09   \n","1             3.0              1.0        202.0  1003214.0  1.002590e+09   \n","2             3.0              2.0         34.0  1005974.0  1.004390e+09   \n","3             3.0              1.0       3001.0  1004323.0  1.003540e+09   \n","4             3.0              2.0       2201.0  1004070.0  1.003350e+09   \n","\n","                                                 NTA        lat        lon  \n","0  Lower East Side                               ...  40.713764 -73.985260  \n","1  Lower East Side                               ...  40.712332 -73.984797  \n","2  East Village                                  ...  40.729783 -73.983041  \n","3  Chinatown                                     ...  40.720569 -73.985673  \n","4  Lower East Side                               ...  40.718725 -73.979426  \n","\n","[5 rows x 167 columns]"]},"metadata":{"tags":[]},"execution_count":124}]},{"metadata":{"id":"lGjaaH8IWptt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c785efd7-a177-4bf0-e92d-54b5f575850e","executionInfo":{"status":"ok","timestamp":1541630772691,"user_tz":120,"elapsed":559,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["combined.shape"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(363, 167)"]},"metadata":{"tags":[]},"execution_count":125}]},{"metadata":{"id":"LoZeRh6W8yF_","colab_type":"text"},"cell_type":"markdown","source":["##  1.14 Filling in Missing Values"]},{"metadata":{"id":"G_P59inq8yF_","colab_type":"text"},"cell_type":"markdown","source":["You may have noticed that the inner joins resulted in 116 fewer rows in **sat_results**. This is because pandas couldn't find the **DBN** values that existed in **sat_results** in the other data sets. While this is worth investigating, we're currently looking for high-level correlations, so we don't need to dive into which **DBNs** are missing.\n","\n","You may also have noticed that we now have many columns with null (**NaN**) values. This is because we chose to do **left** joins, where some columns may not have had data. The data set also had some missing values to begin with. If we hadn't performed a **left** join, all of the rows with missing data would have been lost in the merge process, which wouldn't have left us with many high schools in our data set.\n","\n","There are several ways to handle missing data, and we'll cover them in more detail later on. For now, we'll just fill in the missing values with the overall mean for the column, like so:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1OmhXzMuPrGSmyyugGXpmrRlLznDHxOeT\"></left>\n","\n","In the diagram above, the mean of the first column is (1800 + 1600 + 2200 + 2300) / 4, or 1975, and the mean of the second column is (20 + 30 + 30 + 50) / 4, or 32.5. We replace the missing values with the means of their respective columns, which allows us to proceed with analyses that can't handle missing values (like correlations).\n","\n","We can fill in missing data in pandas using the [pandas.DataFrame.fillna()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) method. This method will replace any missing values in a dataframe with the values we specify. We can compute the mean of every column using the [pandas.DataFrame.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html) method. If we pass the results of the **df.mean()** method into the **df.fillna()** method, pandas will fill in the missing values in each column with the mean of that column.\n","\n","Here's an example of how we would accomplish this:\n","\n","```python\n","means = df.mean()\n","df = df.fillna(means)\n","```\n","\n","Note that if a column consists entirely of null or **NaN** values, pandas won't be able to fill in the missing values when we use the **df.fillna()** method along with the **df.mean()** method, because there won't be a mean.\n","\n","We should fill any **NaN** or null values that remain after the initial replacement with the value 0. We can do this by passing 0 into the **df.fillna()** method.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Calculate the means of all of the columns in **combined** using the **pandas.DataFrame.mean()** method.\n","- Fill in any missing values in **combined** with the means of the respective columns using the **pandas.DataFrame.fillna()** method.\n","- Fill in any remaining missing values in **combined** with 0 using the **df.fillna()** method.\n","- Display the first few rows of **combined** to verify that the correct operations occurred."]},{"metadata":{"id":"XLJ8giWa8yGA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":593},"outputId":"dc4aa703-58b6-4cf3-a455-b178e25499e2","executionInfo":{"status":"ok","timestamp":1541630977610,"user_tz":120,"elapsed":573,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["means = combined.mean()\n","combined = combined.fillna(means)\n","combined = combined.fillna(0)\n","combined.head()"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>SCHOOL NAME</th>\n","      <th>Num of SAT Test Takers</th>\n","      <th>SAT Critical Reading Avg. Score</th>\n","      <th>SAT Math Avg. Score</th>\n","      <th>SAT Writing Avg. Score</th>\n","      <th>sat_score</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>...</th>\n","      <th>priority10</th>\n","      <th>Location 1</th>\n","      <th>Community Board</th>\n","      <th>Council District</th>\n","      <th>Census Tract</th>\n","      <th>BIN</th>\n","      <th>BBL</th>\n","      <th>NTA</th>\n","      <th>lat</th>\n","      <th>lon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n","      <td>29</td>\n","      <td>355.0</td>\n","      <td>404.0</td>\n","      <td>363.0</td>\n","      <td>1122.0</td>\n","      <td>0</td>\n","      <td>129.028846</td>\n","      <td>197.038462</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>220 Henry Street\\nNew York, NY 10002\\n(40.7137...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>201.0</td>\n","      <td>1003223.0</td>\n","      <td>1.002690e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.713764</td>\n","      <td>-73.985260</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>91</td>\n","      <td>383.0</td>\n","      <td>423.0</td>\n","      <td>366.0</td>\n","      <td>1172.0</td>\n","      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n","      <td>39.000000</td>\n","      <td>49.000000</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>200 Monroe Street\\nNew York, NY 10002\\n(40.712...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>202.0</td>\n","      <td>1003214.0</td>\n","      <td>1.002590e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.712332</td>\n","      <td>-73.984797</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>70</td>\n","      <td>377.0</td>\n","      <td>402.0</td>\n","      <td>370.0</td>\n","      <td>1149.0</td>\n","      <td>EAST SIDE COMMUNITY HS</td>\n","      <td>19.000000</td>\n","      <td>21.000000</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>420 East 12 Street\\nNew York, NY 10009\\n(40.72...</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>34.0</td>\n","      <td>1005974.0</td>\n","      <td>1.004390e+09</td>\n","      <td>East Village                                  ...</td>\n","      <td>40.729783</td>\n","      <td>-73.983041</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>44</td>\n","      <td>390.0</td>\n","      <td>433.0</td>\n","      <td>384.0</td>\n","      <td>1207.0</td>\n","      <td>0</td>\n","      <td>129.028846</td>\n","      <td>197.038462</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>145 Stanton Street\\nNew York, NY 10002\\n(40.72...</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3001.0</td>\n","      <td>1004323.0</td>\n","      <td>1.003540e+09</td>\n","      <td>Chinatown                                     ...</td>\n","      <td>40.720569</td>\n","      <td>-73.985673</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M539</td>\n","      <td>NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...</td>\n","      <td>159</td>\n","      <td>522.0</td>\n","      <td>574.0</td>\n","      <td>525.0</td>\n","      <td>1621.0</td>\n","      <td>NEW EXPLORATIONS SCI,TECH,MATH</td>\n","      <td>255.000000</td>\n","      <td>377.000000</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>111 Columbia Street\\nNew York, NY 10002\\n(40.7...</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2201.0</td>\n","      <td>1004070.0</td>\n","      <td>1.003350e+09</td>\n","      <td>Lower East Side                               ...</td>\n","      <td>40.718725</td>\n","      <td>-73.979426</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 167 columns</p>\n","</div>"],"text/plain":["      DBN                                        SCHOOL NAME  \\\n","0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n","1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n","2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n","3  01M509                            MARTA VALLE HIGH SCHOOL   \n","4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n","\n","  Num of SAT Test Takers  SAT Critical Reading Avg. Score  \\\n","0                     29                            355.0   \n","1                     91                            383.0   \n","2                     70                            377.0   \n","3                     44                            390.0   \n","4                    159                            522.0   \n","\n","   SAT Math Avg. Score  SAT Writing Avg. Score  sat_score  \\\n","0                404.0                   363.0     1122.0   \n","1                423.0                   366.0     1172.0   \n","2                402.0                   370.0     1149.0   \n","3                433.0                   384.0     1207.0   \n","4                574.0                   525.0     1621.0   \n","\n","                       SchoolName  AP Test Takers   Total Exams Taken  \\\n","0                               0       129.028846         197.038462   \n","1    UNIVERSITY NEIGHBORHOOD H.S.        39.000000          49.000000   \n","2          EAST SIDE COMMUNITY HS        19.000000          21.000000   \n","3                               0       129.028846         197.038462   \n","4  NEW EXPLORATIONS SCI,TECH,MATH       255.000000         377.000000   \n","\n","     ...      priority10                                         Location 1  \\\n","0    ...               0  220 Henry Street\\nNew York, NY 10002\\n(40.7137...   \n","1    ...               0  200 Monroe Street\\nNew York, NY 10002\\n(40.712...   \n","2    ...               0  420 East 12 Street\\nNew York, NY 10009\\n(40.72...   \n","3    ...               0  145 Stanton Street\\nNew York, NY 10002\\n(40.72...   \n","4    ...               0  111 Columbia Street\\nNew York, NY 10002\\n(40.7...   \n","\n","  Community Board Council District Census Tract        BIN           BBL  \\\n","0             3.0              1.0        201.0  1003223.0  1.002690e+09   \n","1             3.0              1.0        202.0  1003214.0  1.002590e+09   \n","2             3.0              2.0         34.0  1005974.0  1.004390e+09   \n","3             3.0              1.0       3001.0  1004323.0  1.003540e+09   \n","4             3.0              2.0       2201.0  1004070.0  1.003350e+09   \n","\n","                                                 NTA        lat        lon  \n","0  Lower East Side                               ...  40.713764 -73.985260  \n","1  Lower East Side                               ...  40.712332 -73.984797  \n","2  East Village                                  ...  40.729783 -73.983041  \n","3  Chinatown                                     ...  40.720569 -73.985673  \n","4  Lower East Side                               ...  40.718725 -73.979426  \n","\n","[5 rows x 167 columns]"]},"metadata":{"tags":[]},"execution_count":126}]},{"metadata":{"id":"TkFLrp0r8yGG","colab_type":"text"},"cell_type":"markdown","source":["## 1.15 Adding a School District Column for Mapping"]},{"metadata":{"id":"Bhwo7emM8yGG","colab_type":"text"},"cell_type":"markdown","source":["We've finished cleaning and combining our data! We now have a clean data set on which we can base our analysis. Mapping the statistics out on a school district level might be an interesting way to analyze them. Adding a column to the data set that specifies the school district will help us accomplish this.\n","\n","The school district is just the first two characters of the **DBN**. We can apply a function over the **DBN** column of **combined** that pulls out the first two letters.\n","\n","For example, we can use indexing to extract the first few characters of a string, like this:\n","\n","```python\n","name = \"Sinbad\"\n","print(name[0:2])\n","```\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Write a function that extracts the first two characters of a string and returns them.\n","- Apply the function to the **DBN** column of **combined**, and assign the result to the **school_dist** column of **combined**.\n","- Display the first few items in the **school_dist** column of **combined** to verify the results.\n"]},{"metadata":{"id":"gIk75azA8yGG","colab_type":"code","colab":{}},"cell_type":"code","source":["def extract(string):\n","  firsts = string[0:2]\n","  return firsts"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9AB0C5TNYWgU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"683f5bff-23fc-4cf0-e0fd-737c85b39fac","executionInfo":{"status":"ok","timestamp":1541631308067,"user_tz":120,"elapsed":576,"user":{"displayName":"Patrícia Sayonara","photoUrl":"https://lh6.googleusercontent.com/-Nok2sKJe3K4/AAAAAAAAAAI/AAAAAAAAAIU/InX5P5gPmoI/s64/photo.jpg","userId":"01856322366072644782"}}},"cell_type":"code","source":["combined[\"school_dist\"] = combined[\"DBN\"].apply(extract)\n","combined[\"school_dist\"].head()"],"execution_count":129,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    01\n","1    01\n","2    01\n","3    01\n","4    01\n","Name: school_dist, dtype: object"]},"metadata":{"tags":[]},"execution_count":129}]},{"metadata":{"id":"q8407VxT8yGK","colab_type":"text"},"cell_type":"markdown","source":["## 1.16 Next Steps"]},{"metadata":{"id":"0YOOKVLg8yGK","colab_type":"text"},"cell_type":"markdown","source":["We now have a clean data set we can analyze! We've done a lot in this mission. We've gone from having several messy sources to one clean, combined, data set that's ready for analysis.\n","\n","Along the way, we've learned about:\n","\n","- How to handle missing values\n","- Different types of merges\n","- How to condense data sets\n","- How to compute averages across dataframes\n","\n","Data scientists rarely start out with tidy data sets, which makes cleaning and combining them one of the most critical skills any data professional can learn.\n"]}]}